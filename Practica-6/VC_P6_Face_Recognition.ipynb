{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 6\n",
    "## Propuesta: Intento de sistema de reconocimiento facial y reacciones según datos de DeepFace\n",
    "<ul>\n",
    "<li>Nikhil Chandru Durgadas Chellaram</li>\n",
    "<li>Raúl Mateus Sánchez</li>\n",
    "</ul>\n",
    "\n",
    "Para comprobar el desarrollo de la práctica: https://github.com/raulmat19/Vision-por-Computador/tree/main/Practica-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"VGG-Face\",\"Facenet\",\"Facenet512\",\"OpenFace\",\"DeepFace\",\"DeepID\",\"ArcFace\",\"Dlib\",\"SFace\"]\n",
    "\n",
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "\n",
    "backends = ['opencv','ssd','dlib','mtcnn','retinaface','mediapipe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(img, text,\n",
    "          font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "          pos=(0, 0),\n",
    "          font_scale=3,\n",
    "          font_thickness=2,\n",
    "          text_color=(255, 255, 255),\n",
    "          text_color_bg=(0, 0, 0)\n",
    "          ):\n",
    "\n",
    "    x, y = pos\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(img, pos, (x + text_w + 5, y + text_h + 5), text_color_bg, -1)\n",
    "    cv2.putText(img, text, (x, int(y + text_h + font_scale - 1)), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "    return text_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este pequeño sistema, se permite al usuario registrar su cara en el sistema con la finalidad de simular un sistema de reconocimiento facial así como prodecer a las reacciones propuestas empleando las utilidades de DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFace(path, name):\n",
    "    vid = cv2.VideoCapture(0)\n",
    "    counter = 0\n",
    "\n",
    "    while(True):      \n",
    "        # fotograma a fotograma\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        if ret:\n",
    "            draw_text(frame, f\"{counter}\", font_scale=1, pos=(50, 10), text_color_bg=(0, 0, 0))\n",
    "            cv2.imshow('Cam', frame)   \n",
    "\n",
    "        key = cv2.waitKey(5)     \n",
    "        # Detenemos pulsado ESC\n",
    "        if key and key == 27 or counter == 3:\n",
    "            break\n",
    "        elif key and key == 32:\n",
    "            if counter > 0:\n",
    "                new_path = path + '/' + name + str(counter) + '.jpg'\n",
    "            \n",
    "            else:\n",
    "                new_path = path + '/' + name + '.jpg'\n",
    "\n",
    "            cv2.imwrite(new_path, frame)\n",
    "            counter += 1\n",
    "            \n",
    "            \n",
    "    # Libera el objeto de captura\n",
    "    vid.release()\n",
    "    # Destruye ventanas\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_loaded = False\n",
    "\n",
    "data_loaded = input (\"Si su cara ha sido ya registrada, introduzca 'Si'. En caso contrario, introduzca 'No' o cualquier cosa\")\n",
    "if data_loaded == 'Si' or data_loaded == 'si':\n",
    "    face_loaded = True\n",
    "\n",
    "if not face_loaded:\n",
    "    data = False\n",
    "    escape = 0\n",
    "\n",
    "    while not data:\n",
    "\n",
    "        name = input (\"Introduce tu nombre: \")\n",
    "        surname = input (\"Introduce tus apellidos: \")\n",
    "        age = input (\"Introduce tu edad: \")\n",
    "        sexo = input (\"Introduce tu sexo: \")\n",
    "        workingStatus = input (\"Introduce tu ocupación: \")\n",
    "\n",
    "        if name == '' or surname == '' or age == '' or sexo == '' or workingStatus == '':\n",
    "            warning = input (\"Datos incorrectos. Pulse Enter para volver a introducirlos\")\n",
    "            escape += 1\n",
    "        \n",
    "        else:\n",
    "            data = True\n",
    "\n",
    "        if escape >= 2:\n",
    "            break\n",
    "\n",
    "    if data:\n",
    "        try:\n",
    "            dir_path = 'face_recognition_images/' + str(name)\n",
    "            try:\n",
    "                os.stat(dir_path)\n",
    "            except:\n",
    "                os.mkdir(dir_path)\n",
    "            file_path = dir_path + '/info.txt'\n",
    "            with open(file_path, 'w') as f:\n",
    "                f.write(f\"{name}, {surname}, {age}, {sexo}, {workingStatus}\")\n",
    "            f.close()\n",
    "\n",
    "            warning = input (\"Pulse Enter para escanear su cara. Debe sacarse tres fotos, empleando para ello la tecla 'Barra espaciadora'\")\n",
    "            getFace(dir_path, name)\n",
    "\n",
    "        except:\n",
    "            print(\"Fallo del sistema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema de reconocimiento facial, que compara la cara en tiempo real con las caras ya escaneadas y guardadas, y muestra la información del usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/60674501/how-to-make-black-background-in-cv2-puttext-with-python-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showFlag(ruta, img):\n",
    "    flag_list = os.listdir(ruta)\n",
    "    index = np.random.randint(0, len(flag_list))\n",
    "    img_flag = cv2.imread(ruta + \"/\" + flag_list[index])\n",
    "    img_flag = cv2.resize(img_flag, (150, 100))\n",
    "\n",
    "    img[img.shape[0]-100:img.shape[0], img.shape[1]-150:img.shape[1]] = img_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFlag(raza):\n",
    "    if raza == \"white\":\n",
    "        return \"flags_images/white\"\n",
    "    elif raza == \"asian\":\n",
    "        return \"flags_images/asian\"\n",
    "    elif raza == \"indian\":\n",
    "        return \"flags_images/indian\"\n",
    "    elif raza == \"middle eastern\":\n",
    "        return \"flags_images/middle-eastern\"\n",
    "    elif raza == \"latino hispanic\":\n",
    "        return \"flags_images/latino-hispanic\"\n",
    "    elif raza == \"black\":\n",
    "        return \"flags_images/black\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "vid = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "init = False\n",
    "flag_mode = False\n",
    "line = None\n",
    "y0, dy = 10, 4\n",
    "properties = [\"Nombre\", \"Apellidos\", \"Edad\", \"Sexo\", \"Ocupacion\"]\n",
    "\n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if ret:\n",
    "        # Sistema de reconocimiento facial y muestra de información de usuario\n",
    "        if not flag_mode:\n",
    "            if counter == 50 or not init:\n",
    "                cv2.imwrite('cap_faces/face.jpg', frame)\n",
    "\n",
    "                try:\n",
    "                    df = DeepFace.find(img_path = 'cap_faces/face.jpg', db_path = \"face_recognition_images/\", model_name=models[2], distance_metric = metrics[2], prog_bar = False, enforce_detection=False, silent = True)\n",
    "                    path = df.at[0, 'identity']\n",
    "                    info_path = os.path.dirname(path) + \"/info.txt\"\n",
    "                    with open(info_path) as f:\n",
    "                        line = f.readline()\n",
    "                    f.close()\n",
    "\n",
    "                    draw_text(frame, \"Desbloqueado\", font_scale=1, pos=(0, frame.shape[0]-50), text_color_bg=(0, 0, 0))\n",
    "                    for i, line in enumerate(line.split(\", \")):\n",
    "                        y = y0 + i*dy*7\n",
    "                        draw_text(frame, f\"{properties[i]}:  {line}\", font_scale=1, pos=(5, y), text_color_bg=(0, 0, 0))\n",
    "                    \n",
    "                    counter == 0\n",
    "                    init = True\n",
    "\n",
    "                except:\n",
    "                    init = False\n",
    "                    print(\"Not recognised\")\n",
    "\n",
    "            elif init and counter != 50:\n",
    "                \n",
    "                draw_text(frame, \"Desbloqueado\", font_scale=1, pos=(0, frame.shape[0]-50), text_color_bg=(0, 0, 0))\n",
    "                for i, line in enumerate(line.split(\", \")):\n",
    "                    y = y0 + i*dy*7\n",
    "                    draw_text(frame, f\"{properties[i]}:  {line}\", font_scale=1, pos=(5, y), text_color_bg=(0, 0, 0))\n",
    "                \n",
    "                counter += 1\n",
    "\n",
    "        elif flag_mode and init:\n",
    "            cv2.imwrite('cap_faces/frame.jpg', frame)\n",
    "            obj = DeepFace.analyze(img_path = 'cap_faces/frame.jpg', actions = ['age', 'gender', 'race', 'emotion'], enforce_detection=False)\n",
    "            race = obj['dominant_race']\n",
    "            path_to_flag = getFlag(race)\n",
    "            showFlag(path_to_flag, frame)\n",
    "\n",
    "        cv2.imshow('Cam', frame)   \n",
    "                    \n",
    "    # Detenemos pulsado ESC\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key == ord('d'):\n",
    "        if flag_mode:\n",
    "            flag_mode = False\n",
    "            init = False\n",
    "        else:\n",
    "            flag_mode = True\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En desarrollo ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f14c14f5bb585297fdfcdaaaeaadcafe11c5cd5450ffdfd7b77ecf8a16395170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
